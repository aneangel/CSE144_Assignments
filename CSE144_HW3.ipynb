{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 144 Fall 2023 HW 3\n",
    "\n",
    "In this assignment, your goal is to train Convolutional Neural Networks (CNN) to classify CIFAR-10 images. CIFAR-10 is a 10-class image classification dataset with 50,000 training images and 10,000 test images. You can find more info in https://www.cs.toronto.edu/~kriz/cifar.html. You may find more information about PyTorch usage in official documents at https://pytorch.org/tutorials/beginner/basics/intro.html.\n",
    "\n",
    "## Instruction \n",
    "\n",
    "- Submit your assignments onto **Canvas** by the due date.\n",
    "- This is an **individual** assignment. All help from others (from the web, books other than text, or people other than the TA or instructor) must be clearly acknowledged. \n",
    "- Don't change the input and output structure of pre-defined functions. Most coding parts can be finished with about 5-6 lines of codes.\n",
    "- Remember that tuning on the test loss is prohibited.\n",
    "\n",
    "## Rubric\n",
    "\n",
    "The assignment is worth 40 points in total:\n",
    "- Import and split dataset (5 points)\n",
    "- Build dataloader (5 points)\n",
    "- Build Neural Network (10 points)\n",
    "    - init (5 points)\n",
    "    - forward (5 points)\n",
    "- Define loss and optimizer (5 points)\n",
    "- Training and tesing loop (10 points)\n",
    "    - training (5 points)\n",
    "    - testing (5 points)\n",
    "- Regularization (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-1: Import and split dataset\n",
    "Load the CIFAR-10 dataset using `torchvision.datasets.CIFAR10` and use 10% of training images as validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "###### Your codes start here. ####\n",
    "###### Your codes end here. ######\n",
    "assert len(train_dataset) == 45000\n",
    "assert len(val_dataset) == 5000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-2: Build Dataloader\n",
    "Build PyTorch dataloader based on the dataset. Set batchsize to 128. Remember to shuffle the training data, not the validation data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Your codes start here. ######\n",
    "# Convert datasets to DataLoader\n",
    "###### Your codes end here. ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize one image from CIFAR\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-3: Build a neural network.\n",
    "Build your convolutional neural networks by adding some layers. You should use 2 convolution layers and ReLU as the default activation function. The kernel size of both layers should be 3x3. Use 32 and 64 as the number of filters for the first and the second convolutional layers, respectively. Set their stride to be 2. After that, flatten your input and add two more dense layers. There should be 1024 units in the first dense with ReLU activation, and use 10 hidden units in the second dense layer with softmax activation. The requirements are same for the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "    ###### Your code starts here. ######\n",
    "    # layer definition\n",
    "    ###### Your codes end here. ######\n",
    "\n",
    "    def forward(self, x):\n",
    "    ###### Your code starts here. ######\n",
    "    # forwarding definition\n",
    "    ###### Your codes end here. ######\n",
    "\n",
    "model = SimpleCNN()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-4: Define loss and optimizer.\n",
    "use cross_entropy loss and stochastic gradient descent optimizer. Set lr=0.01 and momentum=0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Your code starts here. ######\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "###### Your code ends here. ######"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-5: Training and testing loop.\n",
    "train your model for 20 epochs. The requirements are same for the following questions. If you do not have access to powerful GPUs, it might take 5-10 minutes to finish one epoch. If you feel you are waiting too long, try smaller networks and less epochs for debugging. But DO NOT forget restore your network definition code and n_epochs to its correct form!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_loop(model, train_loader, val_loader, criterion, optimizer):\n",
    "    n_epochs = 20\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            ###### Your code starts here. ######\n",
    "            # do forward-backward propogation, and update the model\n",
    "            ###### Your code starts here. ######\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                ###### Your code starts here. ######\n",
    "                # compute the validation loss and accuracy\n",
    "                ###### Your code starts here. ######\n",
    "                correct += (predicted == labels.squeeze()).sum().item()\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{n_epochs}, Loss: {val_loss/len(val_loader):.4f}, Accuracy: {correct/total:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def test_loop(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            ###### Your code starts here. ######\n",
    "            # compute the validation loss and accuracy\n",
    "            # should be the same as the code for validation set\n",
    "            ###### Your code starts here. ######\n",
    "            correct += (predicted == labels.squeeze()).sum().item()\n",
    "\n",
    "    print(f'Test Loss: {test_loss/len(test_loader):.4f}, Test Accuracy: {correct/total:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(model, train_loader, val_loader, criterion, optimizer)\n",
    "test_loop(model, test_loader, criterion)\n",
    "# the right implementation should reach an accuracy over 60%, on both val and test set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-6 Regularization\n",
    "Add one dropout layer with 0.5 drop rate between the two dense layer. You can keep all other hyperparameters the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "    ###### Your code starts here. ######\n",
    "    # layer definition\n",
    "        super(SimpleCNN, self).__init__()\n",
    "    ###### Your codes end here. ######\n",
    "\n",
    "    def forward(self, x):\n",
    "    ###### Your code starts here. ######\n",
    "    # forwarding definition\n",
    "    ###### Your codes end here. ######\n",
    "\n",
    "model = SimpleCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Your code starts here. ######\n",
    "# do not forget to redefine the loss and optimizer!\n",
    "###### Your code ends here. ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(model, train_loader, val_loader, criterion, optimizer)\n",
    "test_loop(model, test_loader, criterion)\n",
    "# the right implementation should lead to an accuracy boost of at least 1.5%, on both val and test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse144",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
