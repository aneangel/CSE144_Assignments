{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "R3SW8S-xw-ja"
   },
   "source": [
    "# CSE 144 Fall 2023 HW 2\n",
    "\n",
    "In this assignment, your goal is to build a logistic regression classifier on a simple synthetic dataset (included in train.csv and test.csv).\n",
    "\n",
    "## Instruction \n",
    "\n",
    "- Submit your assignments onto **Canvas** by the due date.\n",
    "- This is an **individual** assignment. All help from others (from the web, books other than text, or people other than the TA or instructor) must be clearly acknowledged. \n",
    "- Don't change the input and output structure of pre-defined functions. Most coding parts can be finished with about 5-6 lines of codes. \n",
    "- Remember that tuning on the test loss is prohibited.\n",
    "\n",
    "## Rubric\n",
    "\n",
    "The assignment is worth 65 points in total:\n",
    "- Data (10 points)\n",
    "- Model (45 points)\n",
    "    - initialization (5 points)\n",
    "    - gradient descent (5 points)\n",
    "    - sigmoid (5 points)\n",
    "    - cross-entropy loss (5 points)\n",
    "    - derivative cross-entropy loss (5 points)\n",
    "    - accuracy (5 points)\n",
    "    - Train (10 points)\n",
    "    - Evaluate (5 points)\n",
    "- Trainer (10 points)\n",
    "    - Define trainer and train (5 points)\n",
    "    - Evaluate (5 points)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "DF5DHsvoaqik"
   },
   "source": [
    "# Dataset preparation\n",
    "In the cell below, you will read training and test data. You should spile the dataset into features and labels for each of training, validation, and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1197,
     "status": "ok",
     "timestamp": 1647069864170,
     "user": {
      "displayName": "Chris Liu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhQemSXNy3-8lMOGHAoMnKl5GiUQPYaVv5RZoPlxi4=s64",
      "userId": "18245379379241780097"
     },
     "user_tz": 480
    },
    "id": "O3qPeXtUw76-",
    "outputId": "a24a4dad-b3e4-46a2-eef3-515562b2028f",
    "ExecuteTime": {
     "end_time": "2023-11-03T05:51:40.161682Z",
     "start_time": "2023-11-03T05:51:40.142532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560, 2) (560,)\n",
      "(240, 2) (240,)\n",
      "(200, 2) (200,)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format=\"retina\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def plot_data(x: np.ndarray, y: np.ndarray) -> None:\n",
    "    \"\"\"\n",
    "    Plot a dataset with 2-d feature vectors and binary labels. \n",
    "\n",
    "    Args:\n",
    "        x: 2-d feature vectors\n",
    "        y: 1-d binary labels.\n",
    "    \"\"\"\n",
    "    class0_idx = np.where(y == 0)[0]\n",
    "    class1_idx = np.where(y == 1)[0]\n",
    "    feature0 = x[:, 0]\n",
    "    feature1 = x[:, 1]\n",
    "    plt.scatter(feature0[class0_idx], feature1[class0_idx], label=\"0\")\n",
    "    plt.scatter(feature0[class1_idx], feature1[class1_idx], label=\"1\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_decision_boundary(theta, x) -> None:\n",
    "    \"\"\"\n",
    "    Plot the decision boundary using theta. Use this function with plot_data().\n",
    "\n",
    "    Args:\n",
    "        theta: a 3-d weight vector.\n",
    "        x: 2-d feature vectors, which is used to decide the span of the decision\n",
    "           boundary.\n",
    "    \"\"\"\n",
    "    xx = np.linspace(min(x[:, 0]), max(x[:, 0]))\n",
    "    yy = (-theta[1] / theta[2]) * xx - (theta[0]) / theta[2]\n",
    "    plt.plot(xx, yy, color=\"red\", label=\"boundary\")\n",
    "    plt.ylim(min(x[:, 1]), max(x[:, 1]))\n",
    "\n",
    "\n",
    "# Read datasets and split your training data into train & validation sets. Split\n",
    "# features from labels after that.\n",
    "# ========== YOUR CODE STARTS HERE ==========\n",
    "dataframeTest = pd.read_csv('test.csv')\n",
    "dataframeTrain = pd.read_csv('train.csv')\n",
    "\n",
    "x = dataframeTrain[['feature1', 'feature2']]\n",
    "y = dataframeTrain['label']\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "x_test = dataframeTest[['feature1', 'feature2']]\n",
    "y_test = dataframeTest['label']\n",
    "\n",
    "# ========== YOUR CODE ENDS HERE ==========\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "p9uz4oGuau6p"
   },
   "source": [
    "## Plot training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1647069864171,
     "user": {
      "displayName": "Chris Liu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhQemSXNy3-8lMOGHAoMnKl5GiUQPYaVv5RZoPlxi4=s64",
      "userId": "18245379379241780097"
     },
     "user_tz": 480
    },
    "id": "iyxYPXoxv-Xm",
    "outputId": "6891c5bd-ba9c-42a9-8f96-290cbe4de03b",
    "ExecuteTime": {
     "end_time": "2023-11-03T05:53:29.830599Z",
     "start_time": "2023-11-03T05:53:29.743370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     feature1  feature2\n404 -0.492416  0.518666\n522 -0.001840 -0.145382\n749 -0.221293  0.972006\n426  1.269637  0.087024\n41   1.039589 -1.339735\n..        ...       ...\n71  -0.755011 -1.003978\n106  1.232525  0.434499\n270 -0.467197 -0.815715\n435 -1.046542  1.312218\n102 -0.801888  0.678318\n\n[560 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature1</th>\n      <th>feature2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>404</th>\n      <td>-0.492416</td>\n      <td>0.518666</td>\n    </tr>\n    <tr>\n      <th>522</th>\n      <td>-0.001840</td>\n      <td>-0.145382</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>-0.221293</td>\n      <td>0.972006</td>\n    </tr>\n    <tr>\n      <th>426</th>\n      <td>1.269637</td>\n      <td>0.087024</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>1.039589</td>\n      <td>-1.339735</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>-0.755011</td>\n      <td>-1.003978</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>1.232525</td>\n      <td>0.434499</td>\n    </tr>\n    <tr>\n      <th>270</th>\n      <td>-0.467197</td>\n      <td>-0.815715</td>\n    </tr>\n    <tr>\n      <th>435</th>\n      <td>-1.046542</td>\n      <td>1.312218</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>-0.801888</td>\n      <td>0.678318</td>\n    </tr>\n  </tbody>\n</table>\n<p>560 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "executionInfo": {
     "elapsed": 523,
     "status": "ok",
     "timestamp": 1647069864686,
     "user": {
      "displayName": "Chris Liu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhQemSXNy3-8lMOGHAoMnKl5GiUQPYaVv5RZoPlxi4=s64",
      "userId": "18245379379241780097"
     },
     "user_tz": 480
    },
    "id": "pQ_9N-r9a7Mp",
    "outputId": "d7b9dd37-609f-4780-d29b-073b268f8c72",
    "ExecuteTime": {
     "end_time": "2023-11-03T05:53:38.931738Z",
     "start_time": "2023-11-03T05:53:37.715Z"
    }
   },
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexes/base.py:3653\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3652\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3653\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3654\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/_libs/index.pyx:153\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: '(slice(None, None, None), 0)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mInvalidIndexError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mplot_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m plot_data(x_val, y_val)\n",
      "Cell \u001B[0;32mIn[3], line 20\u001B[0m, in \u001B[0;36mplot_data\u001B[0;34m(x, y)\u001B[0m\n\u001B[1;32m     18\u001B[0m class0_idx \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mwhere(y \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     19\u001B[0m class1_idx \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mwhere(y \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m---> 20\u001B[0m feature0 \u001B[38;5;241m=\u001B[39m \u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m     21\u001B[0m feature1 \u001B[38;5;241m=\u001B[39m x[:, \u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     22\u001B[0m plt\u001B[38;5;241m.\u001B[39mscatter(feature0[class0_idx], feature1[class0_idx], label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/frame.py:3761\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3760\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3761\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3762\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3763\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexes/base.py:3660\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3655\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3656\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3657\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3658\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3659\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m-> 3660\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_indexing_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3661\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexes/base.py:5737\u001B[0m, in \u001B[0;36mIndex._check_indexing_error\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   5733\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_indexing_error\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[1;32m   5734\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_scalar(key):\n\u001B[1;32m   5735\u001B[0m         \u001B[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001B[39;00m\n\u001B[1;32m   5736\u001B[0m         \u001B[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001B[39;00m\n\u001B[0;32m-> 5737\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n",
      "\u001B[0;31mInvalidIndexError\u001B[0m: (slice(None, None, None), 0)"
     ]
    }
   ],
   "source": [
    "plot_data(x_train, y_train)\n",
    "plot_data(x_val, y_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "pqOAWFA_axTP"
   },
   "source": [
    "# Logistic regression\n",
    "You'll complete the missing parts in the eight functions in the `LogisticRegressionTrainer` class below. Note that you are not supposed to return anything in `gradient_descent_step()` but update the parameters. Especially, do not forget to add the regularization term in `cross_entropy_loss()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1647070448836,
     "user": {
      "displayName": "Chris Liu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhQemSXNy3-8lMOGHAoMnKl5GiUQPYaVv5RZoPlxi4=s64",
      "userId": "18245379379241780097"
     },
     "user_tz": 480
    },
    "id": "YZOF6w9lw3zh"
   },
   "outputs": [],
   "source": [
    "class LogisticRegressionTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features: int,\n",
    "        learning_rate: float = 1e-2,\n",
    "        num_epochs: int = 500,\n",
    "        lambd: float = 0.0,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize a logistic regression trainer.\"\"\"\n",
    "        self.lambd = lambd\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.num_features = num_features\n",
    "        self.train_loss_history = []\n",
    "        self.val_loss_history = []\n",
    "        self.train_acc_history = []\n",
    "        self.val_acc_history = []\n",
    "        self.test_loss = None\n",
    "        self.test_acc = None\n",
    "\n",
    "        # Initialize weights for your model. You can use any initialization methods.\n",
    "        # ========== YOUR CODE STARTS HERE ==========\n",
    "        \n",
    "        # ========== YOUR CODE ENDS HERE ==========\n",
    "\n",
    "    def gradient_descent_step(self, x: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Perform a single step of gradient update.\n",
    "\n",
    "        Args:\n",
    "            x: A matrix of features.\n",
    "            y: A vector of labels.\n",
    "        \"\"\"\n",
    "        # ========== YOUR CODE STARTS HERE ==========\n",
    "        # ========== YOUR CODE ENDS HERE ==========\n",
    "\n",
    "    def sigmoid(self, z: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Convert raw model output (logits) to probabilities.\n",
    "\n",
    "        Args:\n",
    "            z: Raw model output (logits).\n",
    "\n",
    "        Returns:\n",
    "            A vector (or float, if your input is a scalar) of probabilties.\n",
    "        \"\"\"\n",
    "        # ========== YOUR CODE STARTS HERE ==========\n",
    "        # ========== YOUR CODE ENDS HERE ==========\n",
    "\n",
    "    def cross_entropy_loss(self, pred: np.ndarray, target: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculates the binary cross-entropy loss given predictions and targets.\n",
    "        The loss function should add the regularization term.\n",
    "\n",
    "        Args:\n",
    "            pred: Predicted labels (probabilities).\n",
    "            target: Ground-truth labels.\n",
    "\n",
    "        Returns:\n",
    "            A scalar of loss.\n",
    "        \"\"\"\n",
    "        assert pred.shape == target.shape\n",
    "        # ========== YOUR CODE STARTS HERE ==========\n",
    "        # ========== YOUR CODE ENDS HERE ==========\n",
    "\n",
    "    def cross_entropy_loss_derivative(self, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate the derivative of the loss function w.r.t. theta. The derivative of the\n",
    "        loss function should also add the derivative of the L2 regularization term.\n",
    "\n",
    "        Args:\n",
    "            x: Feature vectors.\n",
    "            y: Ground-truth labels.\n",
    "\n",
    "        Returns:\n",
    "            A vector with the same dimension as theta, where each element is the\n",
    "            partial derivative of the loss function w.r.t. the corresponding element\n",
    "            in theta.\n",
    "        \"\"\"\n",
    "        # ========== YOUR CODE STARTS HERE ==========\n",
    "        # ========== YOUR CODE ENDS HERE ==========\n",
    "\n",
    "    def accuracy(self, pred: np.ndarray, target: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculates the percentage of matched labels given predictions and targets.\n",
    "\n",
    "        Args:\n",
    "            pred: Predicted labels (rounded probabilities).\n",
    "            target: Ground-truth labels.\n",
    "\n",
    "        Return:\n",
    "            The accuracy score (a float) given the predicted labels and the true labels.\n",
    "        \"\"\"\n",
    "        assert pred.shape == target.shape\n",
    "        # ========== YOUR CODE STARTS HERE ==========\n",
    "        # ========== YOUR CODE ENDS HERE ==========\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        x_train: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "        x_val: np.ndarray,\n",
    "        y_val: np.ndarray,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Run gradient descent for n epochs, where n = self.num_epochs. In every epoch,\n",
    "            1. Update theta.\n",
    "            2. Calculate the training loss & accuracy given the current theta, and append \n",
    "               then to self.train_loss_history and self.train_acc_history.\n",
    "            3. Calculate the validation loss & accuracy given the current theta, and \n",
    "               append then to self.train_loss_history and self.train_acc_history.\n",
    "\n",
    "        If you wish to use the bias trick, please remember to use it before the for loop.\n",
    "\n",
    "        Args:\n",
    "            x_train: Feature vectors for training.\n",
    "            y_train: Ground-truth labels for training.\n",
    "            x_val: Feature vectors for validation.\n",
    "            y_val: Ground-truth labels for validation.\n",
    "        \"\"\"\n",
    "        # ========== YOUR CODE STARTS HERE ==========\n",
    "        # ========== YOUR CODE ENDS HERE ==========\n",
    "\n",
    "    def evaluate(self, x_test: np.ndarray, y_test: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Evaluate the model on test set and store the test loss int self.test_loss and \n",
    "        test accuracy in self.test_acc. In other words, you should get the test loss and accraucy here.\n",
    "\n",
    "        If you used the bias trick in train(), you have to also use it here.\n",
    "\n",
    "        Args:\n",
    "            x_test: Feature vectors for testing.\n",
    "            y_test: Ground-truth labels for testing.\n",
    "        \"\"\"\n",
    "        # ========== YOUR CODE STARTS HERE ==========\n",
    "        # ========== YOUR CODE ENDS HERE =========="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "8DQ5HqSEazeb"
   },
   "source": [
    "## Train a logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "executionInfo": {
     "elapsed": 1558,
     "status": "ok",
     "timestamp": 1647070451241,
     "user": {
      "displayName": "Chris Liu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhQemSXNy3-8lMOGHAoMnKl5GiUQPYaVv5RZoPlxi4=s64",
      "userId": "18245379379241780097"
     },
     "user_tz": 480
    },
    "id": "1knVC-6KkTuV",
    "outputId": "2e8206c3-bc20-4355-b63e-618a1595e654"
   },
   "outputs": [],
   "source": [
    "# Train a logistic regression classifier\n",
    "# ========== YOUR CODE STARTS HERE ==========\n",
    "# ========== YOUR CODE ENDS HERE ==========\n",
    "\n",
    "print(f\"Final train loss: {trainer.train_loss_history[-1]}\")\n",
    "print(f\"Final validation loss: {trainer.val_loss_history[-1]}\")\n",
    "print(f\"Final train acc: {trainer.train_acc_history[-1]}\")\n",
    "print(f\"Final validation acc: {trainer.val_acc_history[-1]}\")\n",
    "\n",
    "plt.plot(np.arange(trainer.num_epochs), trainer.train_loss_history, label=\"Train loss\")\n",
    "plt.plot(np.arange(trainer.num_epochs), trainer.val_loss_history, label=\"Val loss\")\n",
    "plt.title(\"Train & validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(trainer.num_epochs), trainer.train_acc_history, label=\"Train acc\")\n",
    "plt.plot(np.arange(trainer.num_epochs), trainer.val_acc_history, label=\"Val acc\")\n",
    "plt.title(\"Train & validation acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lmXGufdLcTbD"
   },
   "source": [
    "## Plotting decision boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "executionInfo": {
     "elapsed": 869,
     "status": "ok",
     "timestamp": 1643739816723,
     "user": {
      "displayName": "Chris Liu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhQemSXNy3-8lMOGHAoMnKl5GiUQPYaVv5RZoPlxi4=s64",
      "userId": "18245379379241780097"
     },
     "user_tz": 480
    },
    "id": "At9nduYG2-6w",
    "outputId": "bb109932-0c7e-405f-870b-0d797ec52027"
   },
   "outputs": [],
   "source": [
    "# 0 = theta0 + theta1 * x + theta2 * y\n",
    "# y = (-theta0 - theta1 * x) / theta2\n",
    "print(f\"My logistic regression weights: {trainer.theta}\")\n",
    "plot_decision_boundary(trainer.theta, x_val)\n",
    "plot_data(x_val, y_val)\n",
    "\n",
    "model = LogisticRegression(penalty=\"l2\", n_jobs=-1).fit(x_train, y_train)\n",
    "print(f\"Sklearn logisitic regression weights: {np.append(model.intercept_, model.coef_)}\")\n",
    "plot_decision_boundary(np.append(model.intercept_, model.coef_), x_val)\n",
    "plot_data(x_val, y_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "6KEuYFqHa4LD"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1643739816724,
     "user": {
      "displayName": "Chris Liu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhQemSXNy3-8lMOGHAoMnKl5GiUQPYaVv5RZoPlxi4=s64",
      "userId": "18245379379241780097"
     },
     "user_tz": 480
    },
    "id": "ltBpOW90CFJB",
    "outputId": "d3fb478a-266f-4fcc-aaa9-8cd7981bc8c7"
   },
   "outputs": [],
   "source": [
    "# Evaluate your model on the test set\n",
    "# ========== YOUR CODE STARTS HERE ==========\n",
    "# ========== YOUR CODE ENDS HERE ==========\n",
    "print(f\"Test loss: {trainer.test_loss}\")\n",
    "print(f\"Test acc: {trainer.test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PsNphLCphvsD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CSE-144-Assignment-2-Solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
